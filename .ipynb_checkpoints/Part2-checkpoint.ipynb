{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from math import log10\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Active Learning Using Support Vector Machines   \n",
    "   \n",
    "(a) Download the banknote authentication Data Set from: https://archive.ics.uci.edu/ml/datasets/banknote+authentication. Choose 472 data points randomly as the test set, and the remaining 900 points as the training set. This is a\n",
    "binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis  entropy  class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((900, 5), (472, 5))\n"
     ]
    }
   ],
   "source": [
    "df = shuffle(df).reset_index(drop=True)\n",
    "test_data = df[:472]\n",
    "train_data = df[472:]\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_range(x_train, y_train):\n",
    "    c_ = np.logspace(-5, 8, 10)\n",
    "    scores = []\n",
    "    for c in c_:\n",
    "        svc = LinearSVC(penalty='l1', C=c, dual=False)\n",
    "        svc.fit(x_train, y_train)\n",
    "        scores.append(svc.score(x_train, y_train))\n",
    "    scores = np.array(scores)\n",
    "    ind = np.argwhere(scores > 0.9).flatten()\n",
    "    c_1 = c_[ind[0]]\n",
    "    c_2 = c_[ind[-1]]\n",
    "    return c_1, c_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Repeat each of the following two procedures 50 times. You will have 50 errors for\n",
    "90 SVMs per each procedure.   \n",
    "   \n",
    "i. Train a SVM with a pool of 10 randomly selected data points from the training\n",
    "set using linear kernel and L1 penalty. Select the penalty parameter using\n",
    "10-fold cross validation.2 Repeat this process by adding 10 other randomly\n",
    "selected data points to the pool, until you use all the 900 points. Do NOT\n",
    "replace the samples back into the training set at each step. Calculate the\n",
    "test error for each SVM. You will have 90 SVMs that were trained using 10,\n",
    "20, 30, ... , 900 data points and their 90 test errors. You have implemented\n",
    "passive learning.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearSVC(x_train, y_train):\n",
    "    c_l, c_h = get_c_range(x_train, y_train)\n",
    "    parameters = {'C':np.logspace(log10(c_l), log10(c_h), 20)}\n",
    "\n",
    "    svc = LinearSVC(penalty='l1', dual=False)\n",
    "    n_splits = 10 if (len(x_train) > 10) else 5\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "    clf = GridSearchCV(svc, parameters, cv=kf, scoring='accuracy', return_train_score=True)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [2:44:58<00:00, 195.37s/it]  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "test_data = shuffle(test_data)\n",
    "x_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "    each = []\n",
    "    \n",
    "    #First 10 Samples\n",
    "    remaining, pool = train_test_split(train_data, test_size=10)\n",
    "    while(len(pool['class'].unique()) == 1 or pool['class'].value_counts().min() < 2):\n",
    "        remaining, pool = train_test_split(train_data, test_size=10)\n",
    "    clf = linearSVC(pool.iloc[:, :-1], pool['class'])\n",
    "    each.append(1 - clf.score(x_test, y_test))\n",
    "    \n",
    "    for j in range(88):\n",
    "        #Next 10 samples on a loop\n",
    "        remaining, selected = train_test_split(remaining, test_size=10)\n",
    "        pool = pool.append(selected)\n",
    "        clf = linearSVC(pool.iloc[:, :-1], pool['class'])\n",
    "        each.append(1 - clf.score(x_test, y_test))\n",
    "        #print('Test Error {}'.format(1 - round(metrics.accuracy_score(y_test, y_pred), 2)))\n",
    "    \n",
    "    #Training on whole dataset\n",
    "    clf = linearSVC(train_data.iloc[:, :-1], train_data['class'])\n",
    "    each.append(1 - clf.score(x_test, y_test))\n",
    "    \n",
    "    results.append(np.mean(each))\n",
    "pd.DataFrame(results).to_csv('results21.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Train a SVM with a pool of 10 randomly selected data points from the training\n",
    "set3 using linear kernel and L1 penalty. Select the parameters of the SVM\n",
    "with 10-fold cross validation. Choose the 10 closest data points in the training\n",
    "set to the hyperplane of the SVM4 and add them to the pool. Do not replace\n",
    "the samples back into the training set. Train a new SVM using the pool.\n",
    "Repeat this process until all training data is used. You will have 90 SVMs\n",
    "that were trained using 10, 20, 30,..., 900 data points and their 90 test errors.\n",
    "You have implemented active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [2:02:29<00:00, 146.19s/it]  \n"
     ]
    }
   ],
   "source": [
    "results1 = []\n",
    "test_data = shuffle(test_data)\n",
    "x_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "    \n",
    "for i in tqdm(range(50)):\n",
    "    train_data = shuffle(train_data)\n",
    "    train_nottak, train_taken = train_test_split(train_data, test_size=10)\n",
    "    while(len(train_taken['class'].unique()) == 1 or train_taken['class'].value_counts().min() < 2):\n",
    "        train_nottak, train_taken = train_test_split(train_data, test_size=10)\n",
    "    \n",
    "    each = []\n",
    "    \n",
    "    for j in range(90):\n",
    "        #print(x_train_taken.shape, y_train_taken.shape, train_nottak.shape)\n",
    "        sv = linearSVC(train_taken.iloc[:, :-1], train_taken.iloc[:, -1])\n",
    "        \n",
    "        if(j < 89):\n",
    "            dist = sv.decision_function(train_nottak.iloc[:, :-1])\n",
    "            #w_norm = np.linalg.norm(sv.coef_)\n",
    "            #dist = y / w_norm\n",
    "            #dist = [abs(each) for each in dist]\n",
    "            train_nottak['dist'] = dist\n",
    "            train_nottak = train_nottak.sort_values(['dist'], ascending=True)\n",
    "            train_taken = train_taken.append(train_nottak.iloc[:10, :-1])\n",
    "            train_nottak = train_nottak.iloc[10:, :-1]\n",
    "        \n",
    "        each.append(1 - sv.score(x_test, y_test))\n",
    "        #print('Test Error {}'.format(1 - round(metrics.accuracy_score(y_test, y_pred), 2)))\n",
    "    results1.append(np.mean(each))\n",
    "pd.DataFrame(results1).to_csv('results22.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Average the 50 test errors for each of the incrementally trained 90 SVMs in 2(b)i\n",
    "and 2(b)ii. By doing so, you are performing a Monte Carlo simulation. Plot\n",
    "average test error versus number of training instances for both active and passive\n",
    "learners on the same figure and report your conclusions. Here, you are actually\n",
    "obtaining a learning curve by Monte-Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = range(10, 901, 10)\n",
    "\n",
    "plt.plot(num_train, results, label='passive')\n",
    "plt.plot(num_train, results1, label='active')\n",
    "plt.xlabel('number of training instances')\n",
    "plt.ylabel('average test error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = results.values - results1.values\n",
    "plt.plot(num_train, diff)\n",
    "plt.xlabel('number of training instances')\n",
    "plt.ylabel('test error difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "When the number of training instances is small, active learners perform better. As the number of training instances increase, passive learners outperform active learners. When the number of training instances is sufficiently large, the performace active learners and passive learners are basicly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
